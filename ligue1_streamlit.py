import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import matplotlib.pyplot as plt
import seaborn as sns

# -----------------------------
# CONFIG STREAMLIT
# -----------------------------

st.set_page_config(
    page_title="Ligue 2 - Classement live",
    layout="wide"
)


st.markdown(
    "<h1 style='color:#6ADFF7;text-align:center;'> Ligue 1 savoir ‚öΩ</h1>",
    unsafe_allow_html=True
)

st.subheader("Intro")
st.write("Bienvenue sur le projet **Ligue 1 savoir**, r√©alis√© et publi√© par  Steeve  le Dimanche 11 Janvier 2026. Ce projet a pour but de pr√©senter l‚Äôanalyse de donn√©e .  ")
st.write("Nomm√©e ¬´ Ligue 1 savoir ¬ª , car l‚Äôobjectif c‚Äôest le savoir et pas l‚Äôavoir . Nous allons donc essayer de comprendre en profondeur, c‚Äôest quoi la ligue 1 . Pour ceux qui ne savent rien , vraiment rien ‚Ä¶ la ¬´ Ligue 1 ¬ª , c‚Äôest le plus haut niveau du championnat de France de football . ")
st.write(" Le premier chapitre de cette analyse portera sur le tableau  ¬´ Classement G√©n√©ral ¬ª . Ce tableau , r√©sume ce qui se passe d‚Äôune mani√®re g√©n√©ral dans la Ligue 1 . Ce tableau est en streaming live, donc actualis√© en temps r√©el . Les graphiques sont aussi en temps r√©el , seul les l√©gendes de graphique et les titres sont manuels ( actualis√© une fois par mois ). ")
st.subheader("L√©gende des colonnes")
st.write("Voici la l√©gende des colonnes du ¬´ Classement G√©n√©ral ¬ª : ")
st.write("**Equipe** : le nom de l‚Äô√©quipe en question")
st.write("**Rang** : Place dans le classement ")
st.write("**Points** : Nombre de point ( relatif √† la place du classement )")
st.write("**Jou√©s** : Num√©ro de la journ√©e ")
st.write("**Match_gagnee** : Nombre de match gagn√© par l‚Äô√©quipe")
st.write("**Match_nul** : Nombre de match nul r√©alis√© par l‚Äô√©quipe ")
st.write("**Match_perdu** : Nombre de match perdu par l‚Äô√©quipe")
st.write("**But_mis** : Nombre de but marqu√© par l‚Äô√©quipe")
st.write("**But_pris** : Nombre de but pris par l‚Äô√©quipe ")
st.write("**Difference_but** : Soustraction entre le nombre de but marqu√© et le nombre de but pris .")


# -----------------------------
# SCRAPING (AVEC CACHE)
# -----------------------------
@st.cache_data(ttl=3600)
def load_data():
    url = "https://www.maxifoot.fr/resultat-ligue-1-france.htm"
    headers = {
        "User-Agent": "Mozilla/5.0"
    }

    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.content, "html.parser")

    table = soup.find("table", class_="clas1")
    rows = table.find_all("tr")

    data = []
    for row in rows[1:]:
        cols = [c.text.strip() for c in row.find_all("td")]
        if len(cols) == 10:
            data.append(cols)

    columns = [
        "Rang", "Equipe", "Points", "Jou√©s",
        "Match_gagnee", "Match_nul", "Match_perdu",
        "But_mis", "But_pris", "Difference_but"
    ]

    df = pd.DataFrame(data, columns=columns)

    # Conversion types
    int_cols = [
        "Rang", "Points", "Match_gagnee",
        "Match_nul", "Match_perdu",
        "But_mis", "But_pris", "Difference_but"
    ]

    for col in int_cols:
        df[col] = df[col].astype(int)

    df = df.set_index("Equipe")

    return df


df = load_data()

# -----------------------------
# AFFICHAGE
# -----------------------------
st.subheader("üìä Classement g√©n√©ral")
st.dataframe(df, use_container_width=True)









df.sort_values(["But_mis"] , ascending=True)


st.subheader("Faut-il marquer beaucoup pour gagner le championnat ? ( Comparaison Buts mis/ Points final )")
st.write("L√©gende : Ce visuel compare le nombre de buts mis et le nombre de point. Et la r√©ponse est que Lens domine ce championnat mais marque peu. Ce qui est triste car Marseille et Paris FC marque beaucoup sans penser √† gagner le match !")
st.bar_chart(
    df[["But_mis", "Points"]],
    color=["#BEEF4C","#EF6DBD"],
    stack=False
)





import altair as alt

df_reset = df.reset_index()

st.write("L√©gende : Voici un nuage de point et un droite de regression lin√©aire. ")
st.write("Explication : Plus un point est aloign√© de la droite, moins son comportement est normal. Ainsi , Lens, ,Le Havre , Lyon et Metz contredise la th√©orie qu'il faut marquer pour gagner")
points = alt.Chart(df_reset).mark_circle(size=80).encode(
    x=alt.X("But_mis:Q", title="Buts marqu√©s"),
    y=alt.Y("Points:Q", title="Points"),
    color=alt.Color("Equipe:N", legend=None),
    tooltip=["Equipe", "But_mis", "Points"]
)

regression = points.transform_regression(
    "But_mis",
    "Points"
).mark_line(color="red", size=3)

chart = (points + regression).properties(
    width=800,
    height=800
)




col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    st.altair_chart(chart, use_container_width=False)


st.subheader("Quelle √©quipe est la plus ennuyante A ?( Histogramme des matchs nuls)")

st.write("L√©gende: Ce visuel montre quelle sont les √©quipe qui font le plus de match nul . Et c'est Lorient, le Havre et Rennes qui gagnent avec 7 matchs nuls chacun")




import altair as alt

df_sorted = df.sort_values("Match_nul", ascending=True).reset_index()

chart = alt.Chart(df_sorted).mark_bar(color="#b852dd").encode(
    x=alt.X("Equipe:N", sort=None),
    y=alt.Y("Match_nul:Q")
)

st.altair_chart(chart, use_container_width=True)


st.write('R√©ponse :')






st.subheader("Quelle √©quipe est la plus ennuyante B ?(Cammembert des matchs nuls)")

st.write("L√©gende: Ce visuel montre quelle sont les √©quipe qui font le plus de match nul . Et c'est Lorient qui gagne !")

fig, ax = plt.subplots(figsize=(12, 4))

ax.pie(
    df["Match_nul"],
    labels=df.index,
    autopct="%1.1f%%",
    
    startangle=90
)

ax.axis("equal")  # cercle parfait

st.pyplot(fig, use_container_width=False)


st.subheader("Les buts font-ils le classement? (Comparaison Points / Diff√©rence de buts")
st.write("L√©gende : Ce visuel compare la diff√©rence de but et le nombre de point.")

st.bar_chart(
    df[["Points", "Difference_but"]],
    use_container_width=True
)


st.subheader("Faut-il faire des matchs nul pour gagner ?  ")
st.write('L√©gende : Ce visuel compare le nombre de match nul et le nombre de point . Et la r√©ponse est clair, Lens n a pas besion de faire de match nul pour gagner ! ')

st.bar_chart(
    df[["Points", "Match_nul"]],
    color=["#EA61CA","#80AFF1"],
    stack=False
)
st.subheader("Qui aime l'action ? ( Comparaison Buts mis/ But pris )")
st.write('L√©gende : Ce rapport compare les Buts mis et les Buts pris . Ainsi Monaco semble aimer mettre des buts et prendre des but !')
st.bar_chart(
    df[["But_mis", "But_pris"]],
    color=["#BFF640","#E9B771"],
    use_container_width=True
)





col1, col2, col3 = st.columns(3)

with col1:
   
 st.title(" Buts mis")



 fig, ax = plt.subplots(figsize=(20, 8.5))

 sns.boxplot(
    y=df["But_mis"],
    width=0.4,
    linewidth=0.5, 
    whis=1.2,
    flierprops={"markersize": 5},
    ax=ax
 )

 ax.tick_params(axis='both', labelsize=20)
 ax.set_ylabel("Points", fontsize=20)

 ax.set_title("Les buts mis ", fontsize=20)

 st.pyplot(fig)

with col2:
 st.title(" Buts pris")



 fig, ax = plt.subplots(figsize=(20, 8.5))

 sns.boxplot(
    y=df["But_pris"],
    width=0.4,
    linewidth=0.5, 
    whis=1.2,
    flierprops={"markersize": 5},
    ax=ax
 )

 ax.tick_params(axis='both', labelsize=20)
 ax.set_ylabel("Points", fontsize=20)

 ax.set_title("Les buts mis ", fontsize=20)

 st.pyplot(fig)    


with col3:
    

 st.title("Matchs nul ")

 fig, ax = plt.subplots(figsize=(12, 4))

 ax.pie(
    df["Match_nul"],
    labels=df.index,
    autopct="%1.1f%%",
    
    startangle=90
 )

 ax.axis("equal")  # cercle parfait

 st.pyplot(fig, use_container_width=False)


st.subheader("Statistiques descriptives")
st.dataframe(df.describe())






st.write("------------------------------------------------------------------------------------")
st.write("--------------------------------ELDORADO VERSION 1 --------------------------------")
st.write("------------------------------------------------------------------------------------")


import streamlit as st
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import pandas as pd
import time

# -----------------------------
# Cr√©ation du driver
# -----------------------------
def create_driver(headless=True):
    options = Options()
    options.add_argument("--headless")

    return webdriver.Chrome(
        service=Service(ChromeDriverManager().install()),
        options=options
    )

# -----------------------------
# R√©cup√©ration des URLs
# -----------------------------
def get_pharmacy_urls(driver, search_url):
    base_url = "https://www.pagesjaunes.fr"
    urls = []

    driver.get(search_url)
    wait = WebDriverWait(driver, 15)
    wait.until(
        EC.presence_of_all_elements_located(
            (By.CSS_SELECTOR, 'a.bi-denomination.pj-link')
        )
    )

    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(2)

    elements = driver.find_elements(By.CSS_SELECTOR, 'a.bi-denomination.pj-link')

    for e in elements:
        href = e.get_attribute("href")
        if href:
            if href.startswith("/"):
                href = base_url + href
            if "annuaire" not in href:
                urls.append(href)

    return list(set(urls))  # supprime les doublons

# -----------------------------
# Scraping d'une pharmacie
# -----------------------------
def scrape_pharmacy(driver, url):
    driver.get(url)

    # Nom
    try:
        nom = WebDriverWait(driver, 10).until(
            EC.visibility_of_element_located(
                (By.CSS_SELECTOR, "div.col-sm-7.col-md-8.col-lg-9.denom h1")
            )
        ).text.replace("\nOuvrir la tooltip", "").strip()
    except:
        nom = None

    # Adresse(s)
    try:
        elements = driver.find_elements(
            By.CSS_SELECTOR,
            "a.teaser-item.black-icon.address.streetAddress.map-click-zon.pj-lb.pj-link span"
        )
        adresses = [e.text.strip() for e in elements if "Loca" not in e.text]
        adresse_complete = " | ".join(adresses)
    except:
        adresse_complete = None

    return {
        "URL": url,
        "Nom_Entreprise": nom,
        "Adresse": adresse_complete
    }

# -----------------------------
# Scraping global
# -----------------------------
def scrape_all_pharmacies(urls):
    driver = create_driver(headless=True)
    data = []

    try:
        for url in urls:
            data.append(scrape_pharmacy(driver, url))
    finally:
        driver.quit()

    return pd.DataFrame(data)

# -----------------------------
# Fonction principale
# -----------------------------
def main(search_url):
    # üëà Chrome invisible
    driver = create_driver(headless=True)

    try:
        urls = get_pharmacy_urls(driver, search_url)
    finally:
        driver.quit()

    df = scrape_all_pharmacies(urls)
    return df

# -----------------------------
# Interface Streamlit
# -----------------------------
st.set_page_config(page_title="Scraper Pharmacies", layout="wide")
st.title("üíä Scraper Pharmacies ‚Äì PagesJaunes")

with st.form("my_form"):
    reason = st.text_input("Colle ici l'URL PagesJaunes ...")
    submitted = st.form_submit_button("Lancer le scraping")

if submitted:
    st.write("‚åõ ATTENDRE 30 SECONDES ‚Ä¶")
    df = main(reason)
    st.success(f"‚úÖ {len(df)} pharmacies r√©cup√©r√©es")
    st.dataframe(df)
    st.write("-----------")







import streamlit as st      

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pandas as pd
import requests
import time
url = "https://www.pagesjaunes.fr/annuaire/chercherlespros?quoiqui=edition%20de%20logiciel&ou=paris-75&page=2"
options = Options()
options.add_argument("--headless")

driver = webdriver.Chrome(
    service=Service(ChromeDriverManager().install()),
    options=options
)

driver.get(url)
time.sleep(5)  # attendre le chargement JS
base_url = "https://www.pagesjaunes.fr"

# R√©cup√©rer tous les href relatifs et les convertir en URL compl√®tes
elements = driver.find_elements(By.CSS_SELECTOR, 'a.bi-denomination.pj-link')
max_urls = []
for e in elements:
        href = e.get_attribute("href")
        if href.startswith("/"):  # href relatif
            full_url = base_url + href
        else:  # href d√©j√† complet
            full_url = href
        max_urls.append(full_url)  # ajouter tous les liens complets
        print(full_url)


driver.quit()

# La liste finale de tous les liens complets
max_urls
# Filtrer les liens : supprimer ceux contenant "annuaire"
max_urls_filtered = [url for url in max_urls if "annuaire" not in url]

# V√©rifier
max_urls_filtered
df = pd.DataFrame(max_urls_filtered)
st.dataframe(df)
